# ocr_app.py
import os
import re
import threading
import time
import cv2
import pytesseract
import numpy as np

# --- C·∫§U H√åNH TESSERACT (ƒê√£ s·ª≠a cho Linux/Docker) ---
# Th∆∞·ªùng kh√¥ng c·∫ßn set path c·ª©ng n·∫øu tesseract ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ƒë√∫ng c√°ch.

class TimetableOCR:
    def __init__(self):
        self.file_anh_path = None
        self.output_image_path = None

    # L√†m s·∫°ch text
    def clean_and_normalize(self, text):
        text = text.upper()
        replacements = {
            'L': '1', 'I': '1', '|': ' ', 'J': '1',
            'O': '0', 'S': '5', 'Z': '2', 'B': '8',
            ']': '1', '[': '1', '}': '1', '{': '1'
        }
        for a, b in replacements.items():
            text = text.replace(a, b)

        text = re.sub(r"[^A-Z0-9\s]", " ", text)
        text = re.sub(r"\s+", " ", text).strip()
        return text

    # Ki·ªÉm tra kh·ªõp t·ª´ kh√≥a
    def is_match(self, row_text, keyword):
        clean_row = self.clean_and_normalize(row_text)
        clean_key = self.clean_and_normalize(keyword)

        if not any(c.isdigit() for c in clean_key):
            return clean_key in clean_row.split()

        tokens = clean_row.split()
        for idx, token in enumerate(tokens):
            if token.startswith(clean_key):
                return True
            if idx + 1 < len(tokens):
                if (token + tokens[idx+1]).startswith(clean_key):
                    return True
            if clean_key.replace("A", "4") == token or clean_key.replace("4", "A") == token:
                return True

        return False

    # T√¨m c·ªôt ch√≠nh
    def detect_main_columns(self, binary_img, W, H):
        v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, max(3, H // 40)))
        v_lines = cv2.dilate(cv2.erode(binary_img, v_kernel, 1), v_kernel, 1)

        cnts, _ = cv2.findContours(v_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        x_centers = []
        for c in cnts:
            x, y, w, h = cv2.boundingRect(c)
            # Gi·∫£m ng∆∞·ª°ng ph√°t hi·ªán ƒë∆∞·ªùng d·ªçc, gi·∫£m W * 0.4 xu·ªëng W * 0.35
            if h > H * 0.35 and w < W * 0.2:
                x_centers.append(x + w // 2)

        x_centers = sorted(set(x_centers))

        if not x_centers:
            mid = W // 2
            return [0, mid, W]

        bounds = [0] + x_centers + [W]
        bounds = sorted(list(dict.fromkeys(bounds)))

        # Gi·∫£m ng∆∞·ª°ng ph√°t hi·ªán c·ªôt t·ªëi thi·ªÉu
        min_width = W * 0.1
        filtered = [bounds[0]]

        for i in range(1, len(bounds)-1):
            if bounds[i+1] - bounds[i] >= min_width:
                filtered.append(bounds[i])

        filtered.append(bounds[-1])
        return sorted(list(dict.fromkeys(filtered)))

    # H√†m x·ª≠ l√Ω ch√≠nh
    def process_timetable_columns(self, keyword):
        if not self.file_anh_path or not os.path.exists(self.file_anh_path):
            return "L·ªói: File ·∫£nh kh√¥ng t·ªìn t·∫°i!"

        if not keyword:
            return "L·ªói: Ch∆∞a nh·∫≠p t·ª´ kh√≥a!"

        img = cv2.imread(self.file_anh_path)
        if img is None:
            return "L·ªói: Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh!"

        # üöÄ T·ªêI ∆ØU H√ìA RAM CH√çNH: Gi·∫£m SCALE t·ª´ 3 xu·ªëng 2. 
        # Vi·ªác gi·∫£m SCALE gi√∫p gi·∫£m 56% k√≠ch th∆∞·ªõc b·ªô nh·ªõ so v·ªõi SCALE 3 (2^2 vs 3^2).
        SCALE = 2 
        img_big = cv2.resize(img, None, fx=SCALE, fy=SCALE, interpolation=cv2.INTER_CUBIC)
        gray = cv2.cvtColor(img_big, cv2.COLOR_BGR2GRAY)

        # S·ª≠ d·ª•ng k√≠ch th∆∞·ªõc ·∫£nh l·ªõn (ƒë√£ ph√≥ng to)
        W, H = img_big.shape[1], img_big.shape[0]

        # √Åp d·ª•ng ng∆∞·ª°ng tr√™n ·∫£nh x√°m
        bin_inv = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                         cv2.THRESH_BINARY_INV, 15, 5)

        # T√°ch c·ªôt
        col_bounds = self.detect_main_columns(bin_inv, W, H)

        # T√°ch h√†ng
        h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (W // 40, 1))
        h_lines = cv2.dilate(cv2.erode(bin_inv, h_kernel, 1), h_kernel, 1)

        cnts, _ = cv2.findContours(h_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        # Gi·∫£m ng∆∞·ª°ng chi·ªÅu r·ªông ƒë·ªÉ ph√°t hi·ªán h√†ng: W * 0.4 xu·ªëng W * 0.35
        y_coords = [cv2.boundingRect(c)[1] for c in cnts if cv2.boundingRect(c)[2] > W * 0.35]
        y_coords.sort()

        rows = []
        # ƒêi·ªÅu ch·ªânh ng∆∞·ª°ng kho·∫£ng c√°ch gi·ªØa c√°c h√†ng ƒë·ªÉ kh·ªõp v·ªõi ·∫£nh ƒë√£ ph√≥ng to SCALE=2
        # 15 * SCALE = 30
        for i in range(len(y_coords) - 1):
            if y_coords[i+1] - y_coords[i] > 15 * SCALE:
                rows.append((y_coords[i], y_coords[i+1]))

        found = 0
        result_img = img_big.copy()

        # ‚öôÔ∏è T·ªêI ∆ØU H√ìA CPU (Tesseract): S·ª≠ d·ª•ng PSM 7 thay v√¨ PSM 6.
        # PSM 7 (Treat the image as a single text line) th∆∞·ªùng nhanh h∆°n v√† ch√≠nh x√°c h∆°n 
        # khi OCR c√°c v√πng nh·ªè (√¥ trong b·∫£ng).
        custom_config = r'--oem 3 --psm 7' 

        for (y1, y2) in rows:
            for i in range(len(col_bounds) - 1):
                x1, x2 = col_bounds[i], col_bounds[i+1]

                # C·∫Øt v√πng ·∫£nh x√°m (gray) thay v√¨ ·∫£nh nh·ªã ph√¢n (bin_inv) ƒë·ªÉ OCR
                roi = gray[y1+4:y2-4, x1+4:x2-4]
                if roi.size < 8:
                    continue

                try:
                    # Ch√∫ √Ω: C√≥ th·ªÉ t·ªëi ∆∞u h∆°n n·∫øu ch·ªâ OCR ·ªü c·ªôt ƒë·∫ßu ti√™n
                    text = pytesseract.image_to_string(roi, lang="eng", config=custom_config)
                except:
                    text = ""

                if self.is_match(text, keyword):
                    found += 1
                    cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 0, 255), 10)

        # Resize l·∫°i ƒë√∫ng k√≠ch th∆∞·ªõc g·ªëc
        final_img = cv2.resize(result_img, (img.shape[1], img.shape[0]))

        # L∆∞u file
        out_name = f"KetQua_{int(time.time())}_{threading.current_thread().name}.jpg"
        self.output_image_path = os.path.join(os.getcwd(), out_name)
        cv2.imwrite(self.output_image_path, final_img)

        return f"T√¨m ki·∫øm xong! T·ªïng s·ªë √¥ kh·ªõp: {found}"
