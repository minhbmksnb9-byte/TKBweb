# ocr_app.py (ƒê√£ ch·ªânh s·ª≠a)

import os
import re
import threading
import time
import cv2
import numpy as np

# --- PaddleOCR ---
from paddleocr import PaddleOCR

# üöÄ KH·ªûI T·∫†O PADDLEOCR M·ªòT L·∫¶N (GLOBAL) üöÄ
# ƒêi·ªÅu n√†y gi√∫p tr√°nh vi·ªác t·∫£i l·∫°i model trong m·ªói request c·ªßa Flask/Gunicorn
GLOBAL_OCR_ENGINE = PaddleOCR(
    use_angle_cls=False,
    lang='en',          # c√≥ th·ªÉ ƒë·ªïi th√†nh 'vi' n·∫øu b·∫°n c·∫ßn ti·∫øng Vi·ªát
    show_log=False,
    rec_algorithm='CRNN',
    det=False,          # Kh√¥ng c·∫ßn detect v√πng - m√¨nh t·ª± c·∫Øt ROI
    # B·∫ÆT BU·ªòC S·ª¨ D·ª§NG CPU tr√™n h·∫ßu h·∫øt c√°c m√¥i tr∆∞·ªùng deploy mi·ªÖn ph√≠/shared
    # Thay ƒë·ªïi 'use_gpu=False' th√†nh 'use_gpu=False' n·∫øu b·∫°n ch·∫Øc ch·∫Øn kh√¥ng d√πng GPU
    use_gpu=False 
)


class TimetableOCR:
    def __init__(self):
        self.file_anh_path = None
        self.output_image_path = None
        
        # ‚ö†Ô∏è S·ª¨ D·ª§NG INSTANCE OCR ƒê√É KH·ªûI T·∫†O GLOBAL ‚ö†Ô∏è
        self.ocr = GLOBAL_OCR_ENGINE

    # ... (C√°c h√†m clean_and_normalize, is_match, detect_main_columns gi·ªØ nguy√™n) ...
    # ... (B·∫°n c√≥ th·ªÉ b·ªè qua ph·∫ßn n√†y trong file c·ªßa m√¨nh) ...

    # L√†m s·∫°ch text
    def clean_and_normalize(self, text):
        text = text.upper()
        # ... (gi·ªØ nguy√™n logic) ...
        replacements = {
            'L': '1', 'I': '1', '|': ' ', 'J': '1',
            'O': '0', 'S': '5', 'Z': '2', 'B': '8',
            ']': '1', '[': '1', '}': '1', '{': '1'
        }
        for a, b in replacements.items():
            text = text.replace(a, b)
        text = re.sub(r"[^A-Z0-9\s]", " ", text)
        text = re.sub(r"\s+", " ", text).strip()
        return text

    # Ki·ªÉm tra kh·ªõp t·ª´ kh√≥a (y nh∆∞ b·∫£n c≈©)
    def is_match(self, row_text, keyword):
        clean_row = self.clean_and_normalize(row_text)
        clean_key = self.clean_and_normalize(keyword)

        if not any(c.isdigit() for c in clean_key):
            return clean_key in clean_row.split()

        tokens = clean_row.split()
        for idx, token in enumerate(tokens):
            if token.startswith(clean_key):
                return True
            if idx + 1 < len(tokens):
                if (token + tokens[idx+1]).startswith(clean_key):
                    return True
            if clean_key.replace("A", "4") == token or clean_key.replace("4", "A") == token:
                return True
        return False

    # T√¨m c·ªôt ch√≠nh
    def detect_main_columns(self, binary_img, W, H):
        v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, max(3, H // 40)))
        v_lines = cv2.dilate(cv2.erode(binary_img, v_kernel, 1), v_kernel, 1)

        cnts, _ = cv2.findContours(v_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        x_centers = []
        for c in cnts:
            x, y, w, h = cv2.boundingRect(c)
            if h > H * 0.35 and w < W * 0.2:
                x_centers.append(x + w // 2)

        x_centers = sorted(set(x_centers))
        if not x_centers:
            mid = W // 2
            return [0, mid, W]

        bounds = [0] + x_centers + [W]
        bounds = sorted(list(dict.fromkeys(bounds)))

        min_width = W * 0.1
        filtered = [bounds[0]]
        for i in range(1, len(bounds)-1):
            if bounds[i+1] - bounds[i] >= min_width:
                filtered.append(bounds[i])
        filtered.append(bounds[-1])
        return sorted(list(dict.fromkeys(filtered)))

    # H√†m x·ª≠ l√Ω ch√≠nh (gi·ªØ nguy√™n logic)
    def process_timetable_columns(self, keyword):
        if not self.file_anh_path or not os.path.exists(self.file_anh_path):
            return "L·ªói: File ·∫£nh kh√¥ng t·ªìn t·∫°i!"

        if not keyword:
            return "L·ªói: Ch∆∞a nh·∫≠p t·ª´ kh√≥a!"

        img = cv2.imread(self.file_anh_path)
        if img is None:
            return "L·ªói: Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh!"

        SCALE = 2
        img_big = cv2.resize(img, None, fx=SCALE, fy=SCALE, interpolation=cv2.INTER_CUBIC)
        # ‚ö†Ô∏è CHUY·ªÇN ROI SANG BGR TR∆Ø·ªöC KHI TRUY·ªÄN V√ÄO PADDLEOCR ‚ö†Ô∏è
        # PaddleOCR h·ªó tr·ª£ ƒë·ªçc tr·ª±c ti·∫øp t·ª´ numpy array (BGR/RGB)
        # Tuy nhi√™n, ·∫£nh x√°m (gray) th∆∞·ªùng cho k·∫øt qu·∫£ k√©m h∆°n. 
        # Ch√∫ng ta s·∫Ω d√πng ·∫£nh BGR/RGB g·ªëc (img_big) cho ph·∫ßn OCR, 
        # nh∆∞ng v·∫´n gi·ªØ `gray` cho ph·∫ßn ph√°t hi·ªán c·ªôt/d√≤ng.
        
        # Ta d√πng `img_big` (BGR) cho ph·∫ßn OCR thay v√¨ `gray`
        W, H = img_big.shape[1], img_big.shape[0]

        gray = cv2.cvtColor(img_big, cv2.COLOR_BGR2GRAY)
        
        bin_inv = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_MEAN_C,
            cv2.THRESH_BINARY_INV,
            15, 5
        )

        col_bounds = self.detect_main_columns(bin_inv, W, H)

        h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (W // 40, 1))
        h_lines = cv2.dilate(cv2.erode(bin_inv, h_kernel, 1), h_kernel, 1)

        cnts, _ = cv2.findContours(h_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        y_coords = [cv2.boundingRect(c)[1] for c in cnts if cv2.boundingRect(c)[2] > W * 0.35]
        y_coords.sort()

        rows = []
        for i in range(len(y_coords) - 1):
            if y_coords[i+1] - y_coords[i] > 15 * SCALE:
                rows.append((y_coords[i], y_coords[i+1]))

        found = 0
        result_img = img_big.copy()

        # ------------------------
        #        THAY TH·∫æ OCR
        # ------------------------
        def paddle_ocr_text(roi):
            if roi.size == 0:
                return ""
            # PaddleOCR c·∫ßn BGR/RGB. Ta ƒë√£ chuy·ªÉn sang BGR ·ªü d∆∞·ªõi.
            result = self.ocr.ocr(roi, det=False) 
            if result and len(result) > 0 and result[0] is not None and len(result[0]) > 0:
                # PaddleOCR tr·∫£ v·ªÅ [ [[(box)], (text, score)], ... ]
                # Ta c·∫ßn l·∫•y text t·ª´ ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n: result[0][0][1][0] 
                # (ƒë√£ s·ª≠a do c·∫•u tr√∫c output c·ªßa PaddleOCR)
                # Tuy nhi√™n, trong context n√†y (det=False), output c√≥ th·ªÉ l√†:
                # [ ([ [box_info] ], (text, score)) ]
                # Output th·ª±c t·∫ø c·ªßa `ocr(..., det=False)` l√† list c√°c (text, score)
                # D·ª±a v√†o c√°ch b·∫°n code ban ƒë·∫ßu: result[0][0], ta gi·∫£ ƒë·ªãnh n√≥ l√† text.
                # C·∫•u tr√∫c output c·ªßa PaddleOCR khi `det=False` l√†: `[[text, score], ...]`
                return result[0][0] # L·∫•y text c·ªßa k·∫øt qu·∫£ ƒë·∫ßu ti√™n
            return ""

        # Qu√©t t·ª´ng √¥ trong b·∫£ng
        for (y1, y2) in rows:
            for i in range(len(col_bounds) - 1):
                x1, x2 = col_bounds[i], col_bounds[i+1]

                # ‚ö†Ô∏è C·∫ÆT ROI T·ª™ ·∫¢NH M√ÄU G·ªêC (img_big) ho·∫∑c (·∫£nh x√°m `gray`)
                # N·∫øu PaddleOCR c·ªßa b·∫°n ho·∫°t ƒë·ªông t·ªët v·ªõi ·∫£nh x√°m, d√πng `gray`.
                # N·∫øu kh√¥ng, d√πng `img_big`. Th∆∞·ªùng d√πng ·∫£nh m√†u (BGR) t·ªët h∆°n.
                # Ta d√πng `img_big` ·ªü ƒë√¢y.
                roi = img_big[y1+4:y2-4, x1+4:x2-4] 

                try:
                    text = paddle_ocr_text(roi)
                except Exception as e:
                    # In l·ªói ƒë·ªÉ debug n·∫øu c·∫ßn
                    # print(f"OCR Error: {e}")
                    text = ""

                if self.is_match(text, keyword):
                    found += 1
                    cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 0, 255), 10)

        final_img = cv2.resize(result_img, (img.shape[1], img.shape[0]))

        # ‚ö†Ô∏è C·∫¢I THI·ªÜN T√äN FILE CHO WEBSERVER: ƒê·∫£m b·∫£o ch·ªâ d√πng t√™n file, kh√¥ng d√πng os.getcwd()
        # Trong m√¥i tr∆∞·ªùng Docker/Gunicorn, os.getcwd() c√≥ th·ªÉ kh√¥ng ph·∫£i n∆°i mong mu·ªën.
        # Ta s·∫Ω chuy·ªÉn logic qu·∫£n l√Ω ƒë∆∞·ªùng d·∫´n file k·∫øt qu·∫£ sang web_server.py
        
        # ‚ö†Ô∏è T·∫†M TH·ªúI GI·ªÆ L·∫†I LOGIC C≈® NH∆ØNG C·∫¢NH B√ÅO
        # Tuy nhi√™n, `web_server.py` ƒë√£ t·∫°o `RESULT_FOLDER` an to√†n. 
        # Ta s·∫Ω d√πng th∆∞ m·ª•c t·∫°m (temp directory) ho·∫∑c l∆∞u file k·∫øt qu·∫£ ·ªü `/tmp`
        # v√† ƒë·ªÉ `web_server.py` ch·ªãu tr√°ch nhi·ªám di chuy·ªÉn n√≥.

        # Thay v√¨ os.getcwd(), l∆∞u v√†o th∆∞ m·ª•c T·∫†M /tmp ho·∫∑c m·ªôt th∆∞ m·ª•c c·ªë ƒë·ªãnh
        temp_dir = "/tmp" 
        out_name = f"KetQua_{int(time.time())}_{threading.current_thread().name}.jpg"
        self.output_image_path = os.path.join(temp_dir, out_name) 
        
        # ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
        if not os.path.exists(temp_dir):
            os.makedirs(temp_dir)
            
        cv2.imwrite(self.output_image_path, final_img)

        return f"T√¨m ki·∫øm xong! T·ªïng s·ªë √¥ kh·ªõp: {found}"
